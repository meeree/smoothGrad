import torch
import sys
sys.path.append('../../mpn') # Replace with your own relative path.
import int_data as syn
from networks import VanillaBNN
from utils import fit, to_dataset, cutoff_data, get_extreme_data, eval_on_test_set, sliding_window_states, plot_lr_decay, PCA_dim, plot_pca, plot_accuracy, c_vals
from matplotlib import pyplot as plt
import os
from tqdm import tqdm
os.environ['KMP_DUPLICATE_LIB_OK']='True'

toy_params = {
    'data_type': 'retro_context_int', # int, context, retro_context, context_int, retro_context_int, retro_context_anti, cont_int, 
    
    'phrase_length': 50,
    'n_classes': 3,
    'input_type': 'binary',    # one_hot, binary, binary1-1
    'input_size': 50,          # defaults to length of words
    'include_eos': True,

    'stack_phrases': False,
    'n_stack': 1,
    'include_sos': False,
    'n_delay': 0, # Inserts delay words (>0: at end, <0: at beginning)
    'delay_word': '<delay>', # '<delay>' or 'null'

    'uniform_score': True, # Uniform distribution over scores=
}

net_params = {
    # Network Architecture
    'n_inputs': toy_params['input_size'],
    'n_hidden': 128,
    'n_outputs': toy_params['n_classes'],

    'snn_beta': 0.95,
    'filter_length': 50,

    'cuda': True,
}

train_params = {
    'epochs': 1000,

    'batch_size': 64,
    'train_set_size': 3200,
    'valid_set_size': 100,
    'gradient_clip': 10,

    'monitorFreq': 5,
}

if net_params['cuda']:
    print('Using CUDA...')
    device = torch.device('cuda')
else:
    print('Using CPU...')
    device = torch.device('cpu')

# Generate datasets.
trainData, trainOutputMask, toy_params = syn.generate_data(
    train_params['train_set_size'], toy_params, net_params['n_outputs'], 
    verbose=True, auto_balance=False, device=device)
validData, validOutputMask, _ = syn.generate_data(
    train_params['valid_set_size'], toy_params, net_params['n_outputs'], 
    verbose=False, auto_balance=False, device=device)

test_set_size = 100
testData, testOutputMask, _ = syn.generate_data(
    test_set_size, toy_params, net_params['n_outputs'], 
    verbose=False, auto_balance=False, device=device)

import time
import numpy as np
import os

def load_network(net, toy_params, folder_full, specific_epoch = -1):
    import json, glob
    with open(folder_full + '/toy_params.json') as f:
        toy_params = json.load(f)    
        for key, val in toy_params.get('base_word_vals', {}).items():
            toy_params['base_word_vals'][key] = np.array(val)
        for key, val in toy_params.get('word_to_input_vector', {}).items():
            toy_params['word_to_input_vector'][key] = np.array(val)
        
        # Get index of best network and load it
        fl_names = [os.path.basename(fl) for fl in glob.glob(folder_full + '/save_*.pt')]
        fl_names.sort(key = lambda fl: int(fl[5:-3]))
        sd = torch.load(folder_full + '/' + fl_names[-1])
        hist = sd['hist']
        plot_accuracy(hist)
        plot_lr_decay(hist)
        
        if specific_epoch >= 0:
            net_idx = specific_epoch
        else:
            net_idx = np.argmax(hist['avg_valid_acc'])
            
        fl = folder_full + '/save_' + str(net_idx) + '.pt'
        sd = torch.load(fl)
        sd.pop('hist')
        net.load_state_dict(sd)
        net = net.to('cuda')
        
    return net, toy_params

def evaluate_network(net, toy_params, folder_full, specific_epoch = -1):
    import json, glob
    with open(folder_full + '/toy_params.json') as f:
        toy_params = json.load(f)    
        for key, val in toy_params.get('base_word_vals', {}).items():
            toy_params['base_word_vals'][key] = np.array(val)
        for key, val in toy_params.get('word_to_input_vector', {}).items():
            toy_params['word_to_input_vector'][key] = np.array(val)
        
        # Get index of best network and load it
        fl_names = [os.path.basename(fl) for fl in glob.glob(folder_full + '/save_*.pt')]
        fl_names.sort(key = lambda fl: int(fl[5:-3]))
        sd = torch.load(folder_full + '/' + fl_names[-1])
        hist = sd['hist']
        plot_accuracy(hist)
        plot_lr_decay(hist)
        
        if specific_epoch >= 0:
            net_idx = specific_epoch
        else:
            net_idx = np.argmax(hist['valid_acc'])

            # Adjust since the outputting to files versus to loss plot is at different rates.
            net_idx = int(net_idx * (len(fl_names) / float(len(hist['valid_acc']))))

            
        fl = folder_full + '/save_' + str(net_idx) + '.pt'
        sd = torch.load(fl)
        sd.pop('hist')
        net.load_state_dict(sd)
        net = net.to('cuda')

        for param in net.params:
            param.set_params(1, 0.0)
            param.noisify()

        testData, testOutputMask, _ = syn.generate_data(
                test_set_size, toy_params, net_params['n_outputs'], 
                verbose=False, auto_balance=False, device='cuda')

        net.save = False # Turn off autosaving
        net.plot = False # Turn off plotting
        accuracy = net.accuracy(testData[:,:,:])
        print(accuracy)
        
    return net, toy_params
        
def analyze_network_discrete(folder = '', specific_epoch = -1):
    global toy_params
    global trainData, validData, trainOutputMask, validOutputMask

    folder_full = 'SAVES/' + folder

    # TODO: SET TRUNC, DELAY, ETC FOR LONG TIME FRAME TASK        
    toy_params['phrase_length'] = 50
    net_params['filter_length'] = 100
    
    import json, glob
    net_params['cuda'] = True
    net_params['use_snn'] = False
    net_params['n_per_step'] = 40
    toy_params['n_classes'] = 3
    net_params['n_outputs'] = toy_params['n_classes']
    # net_params['loss_fn'] = 'mse'
    train_params['lr'] = 5e-4   
    train_params['batch_size'] = 50
    train_params['scheduler'] = 'reducePlateau'
    net_params['softmax'] = False
    net = VanillaBNN(net_params, device='cuda').to('cuda')
    net, toy_params = evaluate_network(net, toy_params, folder_full)
 
analyze_network_discrete('song_all_lr0.005_std0.1_S100', True)
